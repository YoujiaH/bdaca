{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First steps with word embeddings\n",
    "Big Data and Automated Content Analysis\n",
    "\n",
    "Damian Trilling\n",
    "\n",
    "\n",
    "This notebook shows you some first steps of how to work with word embeddings in Gensim. \n",
    "\n",
    "\n",
    "**NB  Some of these things may take a lot of memory and/or computing power. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training word embeddings\n",
    "Training word embedings with gensim is very simple (see example code below - even though you wildo l need to specift some extra options). However, you need a massive dataset for that (think of millions of documents). We're therefore not going to do this in class.\n",
    "\n",
    "```\n",
    "model = gensim.models.Word2Vec()\n",
    "model.build_vocab(sentences)\n",
    "model.train(sentences)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pre-trained models\n",
    "We can use pre-trained embeddings instead. You can either download them yourself and then read them from a file (which you probably want to do if you want, for instance, use our Dutch embeddings that we talked about). \n",
    "But we can also use some embeddings that come with gensim and that gensim downloads for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "model = api.load(\"glove-wiki-gigaword-100\")\n",
    "\n",
    "# alternative that is 16 times as big:\n",
    "# model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "# model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word similarities\n",
    "Let's play around with word similarieties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dog', 0.8798074722290039),\n",
       " ('rabbit', 0.7424426674842834),\n",
       " ('cats', 0.7323004007339478),\n",
       " ('monkey', 0.7288709878921509),\n",
       " ('pet', 0.7190139889717102),\n",
       " ('dogs', 0.7163872718811035),\n",
       " ('mouse', 0.6915250420570374),\n",
       " ('puppy', 0.6800068020820618),\n",
       " ('rat', 0.6641027331352234),\n",
       " ('spider', 0.6501135230064392)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A cat is almost the same as a dog.\n",
      "A dog is almost the same as a cat.\n",
      "A horse is almost the same as a horses.\n",
      "A goldfish is almost the same as a crackers.\n",
      "A lion is almost the same as a dragon.\n"
     ]
    }
   ],
   "source": [
    "animals = ['cat', 'dog', 'horse', 'goldfish', 'lion']\n",
    "for animal in animals:\n",
    "    print(\"A {} is almost the same as a {}.\".format(animal, model.most_similar(animal)[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['woman']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.closer_than('man','boy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20851284265518188\n",
      "0.1676505208015442\n"
     ]
    }
   ],
   "source": [
    "print(model.distance('man','boy'))\n",
    "print(model.distance('man','woman'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, as we discussed in the lecture, we can literally calculate with the embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7698541283607483),\n",
       " ('monarch', 0.6843380928039551),\n",
       " ('throne', 0.6755735874176025),\n",
       " ('daughter', 0.6594556570053101),\n",
       " ('princess', 0.6520534753799438),\n",
       " ('prince', 0.6517034769058228),\n",
       " ('elizabeth', 0.6464517712593079),\n",
       " ('mother', 0.6311717629432678),\n",
       " ('emperor', 0.6106470823287964),\n",
       " ('wife', 0.6098655462265015)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 0.8551837205886841),\n",
       " ('queen', 0.783441424369812),\n",
       " ('monarch', 0.6933802366256714),\n",
       " ('throne', 0.6833109855651855),\n",
       " ('daughter', 0.680908203125),\n",
       " ('prince', 0.6713142395019531),\n",
       " ('princess', 0.664408266544342),\n",
       " ('mother', 0.6579325199127197),\n",
       " ('elizabeth', 0.6563301086425781),\n",
       " ('father', 0.6392419338226318)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can do the same by hand, but would need to do some manual cleanup afterwards\n",
    "# (e.g., removing 'king' itself from the results)\n",
    "model.similar_by_vector(model.get_vector('king') - model.get_vector('man') + model.get_vector('woman') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY YOURSELF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using word embeddings in supervised machine learning \n",
    "\n",
    "We need to `sudo pip3 install embeddingvectorizer` first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "import embeddingvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 12500 positive reviews\n",
      "Added 12500 negative reviews\n",
      "Added 12500 positive reviews\n",
      "Added 12500 negative reviews\n"
     ]
    }
   ],
   "source": [
    "reviews=[]\n",
    "test=[]\n",
    "\n",
    "for file in glob (\"/home/damian/Downloads/aclImdb/train/pos/*.txt\"):\n",
    "    with open(file) as fi:\n",
    "        reviews.append((fi.read(),\"1\"))\n",
    "nopostr=len(reviews)\n",
    "print (\"Added\",nopostr,\"positive reviews\")  \n",
    "\n",
    "for file in glob (\"/home/damian/Downloads/aclImdb/train/neg/*.txt\"):\n",
    "    with open(file) as fi:\n",
    "        reviews.append((fi.read(),\"-1\"))\n",
    "nonegtr=len(reviews)-nopostr\n",
    "print (\"Added\",nonegtr,\"negative reviews\")  \n",
    "\n",
    "for file in glob (\"/home/damian/Downloads/aclImdb/test/pos/*.txt\"):\n",
    "    with open(file) as fi:\n",
    "        test.append((fi.read(),\"1\"))\n",
    "noposte=len(test)\n",
    "print (\"Added\",noposte,\"positive reviews\")  \n",
    "\n",
    "for file in glob (\"/home/damian/Downloads/aclImdb/test/neg/*.txt\"):\n",
    "    with open(file) as fi:\n",
    "        test.append((fi.read(),\"-1\"))\n",
    "nonegte=len(test)-noposte\n",
    "print (\"Added\",nonegte,\"negative reviews\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's look at our old model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:\n",
      "0.8598565139409751\n",
      "Recall:\n",
      "0.84376\n"
     ]
    }
   ],
   "source": [
    "mypipe = Pipeline([('vectorizer', TfidfVectorizer()),\n",
    "                    ('svm', \n",
    "                     SGDClassifier(loss='hinge', penalty='l2', tol=1e-4, alpha=1e-6, max_iter=1000, random_state=42))])\n",
    "\n",
    "# Generate BOW representation of word counts\n",
    "mypipe.fit([e[0] for e in reviews], [e[1] for e in reviews])\n",
    "predictions = mypipe.predict([e[0] for e in test])\n",
    "\n",
    "print('Precision:')\n",
    "print(metrics.precision_score([e[1] for e in test],predictions,pos_label='1', labels = ['-1','1']))\n",
    "print('Recall:')\n",
    "print(metrics.recall_score([e[1] for e in test],predictions,pos_label='1', labels = ['-1','1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's compare with the new one.\n",
    "First, we need to convert our word embedding model to the so-called word2vec format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#bigmodel = api.load(\"word2vec-google-news-300\")\n",
    "# w2vmodel = dict(zip(bigmodel.index2word, bigmodel.syn0))\n",
    "\n",
    "w2vmodel = dict(zip(model.index2word, model.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:\n",
      "0.8468904556455856\n",
      "Recall:\n",
      "0.64384\n"
     ]
    }
   ],
   "source": [
    "mypipe = Pipeline([('vectorizer', embeddingvectorizer.EmbeddingTfidfVectorizer(w2vmodel, operator='mean')),\n",
    "                    ('svm', \n",
    "                     SGDClassifier(loss='hinge', penalty='l2', tol=1e-4, alpha=1e-6, max_iter=1000, random_state=42))])\n",
    "\n",
    "# Generate BOW representation of word counts\n",
    "mypipe.fit([e[0] for e in reviews], [e[1] for e in reviews])\n",
    "predictions = mypipe.predict([e[0] for e in test])\n",
    "\n",
    "print('Precision:')\n",
    "print(metrics.precision_score([e[1] for e in test],predictions,pos_label='1', labels = ['-1','1']))\n",
    "print('Recall:')\n",
    "print(metrics.recall_score([e[1] for e in test],predictions,pos_label='1', labels = ['-1','1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, these embeddings seem to be crap. Let's use the new ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "bigmodel = api.load(\"word2vec-google-news-300\")\n",
    "w2vmodel = dict(zip(bigmodel.index2word, bigmodel.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:\n",
      "0.9180983252296057\n",
      "Recall:\n",
      "0.67976\n"
     ]
    }
   ],
   "source": [
    "mypipe = Pipeline([('vectorizer', embeddingvectorizer.EmbeddingTfidfVectorizer(w2vmodel, operator='mean')),\n",
    "                    ('svm', \n",
    "                     SGDClassifier(loss='hinge', penalty='l2', tol=1e-4, alpha=1e-6, max_iter=1000, random_state=42))])\n",
    "\n",
    "# Generate BOW representation of word counts\n",
    "mypipe.fit([e[0] for e in reviews], [e[1] for e in reviews])\n",
    "predictions = mypipe.predict([e[0] for e in test])\n",
    "\n",
    "print('Precision:')\n",
    "print(metrics.precision_score([e[1] for e in test],predictions,pos_label='1', labels = ['-1','1']))\n",
    "print('Recall:')\n",
    "print(metrics.recall_score([e[1] for e in test],predictions,pos_label='1', labels = ['-1','1']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
